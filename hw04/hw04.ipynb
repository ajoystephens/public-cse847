{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0fcabe-ca65-4665-9b9f-40393c8e22d8",
   "metadata": {},
   "source": [
    "# CSE847 Homework 4 - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f984d67-56cc-476a-a86d-8d4eac5efde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8425ce09-b50f-41e6-8973-d981e87d8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FROM HW DESCRIPTION\n",
    "# %\n",
    "# % code to train a logistic regression classifier\n",
    "# %\n",
    "# % INPUTS:\n",
    "# % data = n * (d+1) matrix withn samples and d features, where\n",
    "# %    column d+1 is all ones (corresponding to the intercept term)\n",
    "# % labels = n * 1 vector of class labels (taking values 0 or 1)\n",
    "# % epsilon = optional argument specifying the convergence\n",
    "# %    criterion - if the change in the absolute difference in\n",
    "# %    predictions, from one iteration to the next, averaged across\n",
    "# %    input features, is less than epsilon, then halt\n",
    "# %    (if unspecified, use a default value of 1e-5)\n",
    "# % maxiter = optional argument that specifies the maximum number of\n",
    "# %    iterations to execute (useful when debugging in case your\n",
    "# %    code is not converging correctly!)\n",
    "# %    (if unspecified can be set to 1000)\n",
    "# %\n",
    "# % OUTPUT:\n",
    "# % weights = (d+1) * 1 vector of weights where the weights correspond to\n",
    "# %    the columns of \"data\"\n",
    "# %\n",
    "\n",
    "def logistic_train(data, labels, epsilon=1e-5, maxiter=1000):\n",
    "    ones = np.ones(data.shape[0])[...,None]\n",
    "    X = np.append(ones, data, 1)  # add the intitial column of ones\n",
    "    \n",
    "    w = np.zeros(X.shape[1])  # initialize weights to zero\n",
    "    eta = 1\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        p_old = logistic_predict(data,w)\n",
    "        gradient = getGradient(X,labels,w)   # compute the gradient\n",
    "        w = w + eta*(-1)*gradient            # update weights\n",
    "        p_new = logistic_predict(data,w)\n",
    "        if (np.absolute(p_old-p_new).mean()<epsilon): break\n",
    "    print(\" Training Complete:\",i,\"iterations\")\n",
    "    return(w)\n",
    "\n",
    "def logistic_predict(X,w,returnProb=False):\n",
    "    ones = np.ones(X.shape[0])[...,None]\n",
    "    X = np.append(ones, X, 1)  # add the intitial column of ones\n",
    "    \n",
    "    s = np.matmul(X,w)\n",
    "    p = sigmoid(s) # probability that y = +1 \n",
    "    if returnProb == False: # map probabilities to predictions\n",
    "        # arr[arr > 255] = x\n",
    "        p[p>=0.5] = 1\n",
    "        p[p<0.5] = -1\n",
    "        \n",
    "    return(p)\n",
    "\n",
    "def getGradient(X,y,w):\n",
    "    n = y.shape[0]\n",
    "    s = np.matmul(X,w)\n",
    "    s = np.multiply(-y,s)\n",
    "    s = sigmoid(s)\n",
    "    g = np.multiply(-y,s)\n",
    "    g = np.matmul(g,X)\n",
    "    g = (1/n)*g\n",
    "    return(g)\n",
    "\n",
    "def sigmoid(s):\n",
    "    e = np.exp(-s)\n",
    "    return(1/(1+e))\n",
    "\n",
    "def getAccuracy(actual, pred):\n",
    "    accuracy = (actual == pred).sum() / pred.shape[0]\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9de44f1-3744-4536-9857-e65e8579f94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Complete: 1 iterations\n",
      "w: [ 0.         -0.46891175  0.46891175]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1., -1., -1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST WITH BASIC DATA\n",
    "X = np.array([[1, 2], [3, 4], [2, 1], [4,3]])\n",
    "y = np.array([1,1,-1,-1])\n",
    "w = np.array([1,1])\n",
    "ones = np.ones(X.shape[0])[...,None]\n",
    "np.append(ones, X, 1)\n",
    "w = logistic_train(X,y,maxiter=1000)\n",
    "print('w:',w)\n",
    "logistic_predict(X,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6136fa0-8fdc-48eb-9305-ecb7b030034c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 57)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET SPAM DATASET\n",
    "X_file = 'data/spam/data.txt'\n",
    "y_file = 'data/spam/labels.txt'\n",
    "\n",
    "X_spam = np.loadtxt(X_file)\n",
    "y_spam = np.loadtxt(y_file)\n",
    "y_spam[y_spam==0] = -1        # adjust data labels to be [-1,1], not [0,1]\n",
    "X_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef543d83-1aa7-4795-80ca-5f684276e091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- N = 200 ------------------------------------------\n",
      " Train Dataset Size: 200\n",
      " Training Complete: 20 iterations\n",
      " Train Accuracy: 0.924789820495342\n",
      " Test Accuracy: 0.915\n",
      "----- N = 500 ------------------------------------------\n",
      " Train Dataset Size: 500\n",
      " Training Complete: 14 iterations\n",
      " Train Accuracy: 0.9229456230187759\n",
      " Test Accuracy: 0.908\n",
      "----- N = 800 ------------------------------------------\n",
      " Train Dataset Size: 800\n",
      " Training Complete: 14 iterations\n",
      " Train Accuracy: 0.9234411996842936\n",
      " Test Accuracy: 0.9225\n",
      "----- N = 1000 ------------------------------------------\n",
      " Train Dataset Size: 1000\n",
      " Training Complete: 23 iterations\n",
      " Train Accuracy: 0.9255762288253263\n",
      " Test Accuracy: 0.927\n",
      "----- N = 1500 ------------------------------------------\n",
      " Train Dataset Size: 1500\n",
      " Training Complete: 19 iterations\n",
      " Train Accuracy: 0.927765237020316\n",
      " Test Accuracy: 0.9193333333333333\n",
      "----- N = 2000 ------------------------------------------\n",
      " Train Dataset Size: 2000\n",
      " Training Complete: 9 iterations\n",
      " Train Accuracy: 0.9173394848135332\n",
      " Test Accuracy: 0.9195\n"
     ]
    }
   ],
   "source": [
    "# TEST WITH DIFFERENT SIZE TRAINING DATASETS\n",
    "split_options = [200, 500, 800, 1000, 1500, 2000]\n",
    "X = X_spam\n",
    "y = y_spam\n",
    "\n",
    "\n",
    "for split in split_options:\n",
    "    print('----- N = '+str(split)+' ------------------------------------------')\n",
    "    # split the data\n",
    "    X_train = X[split:,:]\n",
    "    y_train = y[split:]\n",
    "    X_test = X[:split,:]\n",
    "    y_test = y[:split]\n",
    "    \n",
    "    print(' Train Dataset Size: '+str(y_test.shape[0]))\n",
    "    \n",
    "    w = logistic_train(X_train,y_train)\n",
    "    pred_train = logistic_predict(X_train,w)\n",
    "    acc_train = getAccuracy(y_train, pred_train)\n",
    "    print(' Train Accuracy: '+str(acc_train))\n",
    "          \n",
    "    pred_test = logistic_predict(X_test,w)\n",
    "    acc_test = getAccuracy(y_test, pred_test)\n",
    "    print(' Test Accuracy: '+str(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6a5a7-f4ef-4d13-9cac-cca65d3c2c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
